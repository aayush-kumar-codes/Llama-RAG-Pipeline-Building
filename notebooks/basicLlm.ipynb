{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Objectives:\n",
    " 1. Prompt engineering using GPT3.5, and GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "import os\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '4'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '2'\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<Your API Key\"\n",
    "import openai\n",
    "openai.api_key = \"<Your API Key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='d:\\\\LLMOps\\\\Udemy\\\\LLAMAINDEXSCRIPTS\\\\myenv\\\\Lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "load_verify_locations cafile='d:\\\\LLMOps\\\\Udemy\\\\LLAMAINDEXSCRIPTS\\\\myenv\\\\Lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': <MessageRole.USER: 'user'>, 'content': 'What is AI?'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 250, 'stream': False, 'temperature': 0.0}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': <MessageRole.USER: 'user'>, 'content': 'What is AI?'}], 'model': 'gpt-3.5-turbo', 'max_tokens': 250, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D64401A7B0>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D64401A7B0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000002D644B79850> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x000002D644B79850> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D642337B60>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D642337B60>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Dec 2023 07:43:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-0ljlslfzfwnke6ke8t6tuywh'), (b'openai-processing-ms', b'7624'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-limit-tokens_usage_based', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59746'), (b'x-ratelimit-remaining-tokens_usage_based', b'59746'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'254ms'), (b'x-ratelimit-reset-tokens_usage_based', b'254ms'), (b'x-request-id', b'1d8ced7078108894385545af6a45fc91'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=drOccoNj4PftP0NajWnnCDPtyE2zDr2lv.OXDbeCaQ4-1702539820-1-AVDZA78ielUXfBo3ozKyfarywip75bjy1mo+9g9lcPfQSD12C6jXw2AIYB6pV8R6SYxrMO5WxNuyZNVc2Hdszpg=; path=/; expires=Thu, 14-Dec-23 08:13:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=6HS.mmVsEDq2WEVQtCrFPxBvjmNoMp8OmhGrZlXeYRg-1702539820044-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8354d101ca7e3c12-BLR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Dec 2023 07:43:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0613'), (b'openai-organization', b'user-0ljlslfzfwnke6ke8t6tuywh'), (b'openai-processing-ms', b'7624'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-limit-tokens_usage_based', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59746'), (b'x-ratelimit-remaining-tokens_usage_based', b'59746'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'254ms'), (b'x-ratelimit-reset-tokens_usage_based', b'254ms'), (b'x-request-id', b'1d8ced7078108894385545af6a45fc91'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=drOccoNj4PftP0NajWnnCDPtyE2zDr2lv.OXDbeCaQ4-1702539820-1-AVDZA78ielUXfBo3ozKyfarywip75bjy1mo+9g9lcPfQSD12C6jXw2AIYB6pV8R6SYxrMO5WxNuyZNVc2Hdszpg=; path=/; expires=Thu, 14-Dec-23 08:13:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=6HS.mmVsEDq2WEVQtCrFPxBvjmNoMp8OmhGrZlXeYRg-1702539820044-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8354d101ca7e3c12-BLR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms import OpenAI, ChatMessage\n",
    "\n",
    "llm = OpenAI(temperature=0 , model=\"gpt-3.5-turbo\", max_tokens=250)\n",
    "response = llm.complete(\"What is AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or Artificial Intelligence, refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It involves the development of computer systems capable of performing tasks that typically require human intelligence, such as speech recognition, decision-making, problem-solving, and language translation. AI can be categorized into two types: Narrow AI, which is designed for specific tasks, and General AI, which possesses the ability to understand, learn, and apply knowledge across various domains.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-8VafUcUjSnL5vLF996pZo2sZ30W67', 'choices': [Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='AI, or Artificial Intelligence, refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It involves the development of computer systems capable of performing tasks that typically require human intelligence, such as speech recognition, decision-making, problem-solving, and language translation. AI can be categorized into two types: Narrow AI, which is designed for specific tasks, and General AI, which possesses the ability to understand, learn, and apply knowledge across various domains.', role='assistant', function_call=None, tool_calls=None))], 'created': 1702539812, 'model': 'gpt-3.5-turbo-0613', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=95, prompt_tokens=11, total_tokens=106)}\n"
     ]
    }
   ],
   "source": [
    "print(response.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='d:\\\\LLMOps\\\\Udemy\\\\LLAMAINDEXSCRIPTS\\\\myenv\\\\Lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "load_verify_locations cafile='d:\\\\LLMOps\\\\Udemy\\\\LLAMAINDEXSCRIPTS\\\\myenv\\\\Lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': <MessageRole.SYSTEM: 'system'>, 'content': 'Talk like a hippie'}, {'role': <MessageRole.USER: 'user'>, 'content': 'Tell me about AI'}], 'model': 'gpt-4', 'max_tokens': 250, 'stream': False, 'temperature': 0.0}}\n",
      "Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': <MessageRole.SYSTEM: 'system'>, 'content': 'Talk like a hippie'}, {'role': <MessageRole.USER: 'user'>, 'content': 'Tell me about AI'}], 'model': 'gpt-4', 'max_tokens': 250, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D643AC16A0>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D643AC16A0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000002D644B8F6D0> server_hostname='api.openai.com' timeout=60.0\n",
      "start_tls.started ssl_context=<ssl.SSLContext object at 0x000002D644B8F6D0> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D62FA61970>\n",
      "start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002D62FA61970>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Dec 2023 07:52:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b'user-0ljlslfzfwnke6ke8t6tuywh'), (b'openai-processing-ms', b'9266'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-limit-tokens_usage_based', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9739'), (b'x-ratelimit-remaining-tokens_usage_based', b'9739'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'1.566s'), (b'x-ratelimit-reset-tokens_usage_based', b'1.566s'), (b'x-request-id', b'8f127b877565c58f925f0a6dcaf320ff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pAOhsZXdVSmwy4NNrrHijqZ9n6mhgBjJpQcSJS9r7F0-1702540336-1-AZHtBy4+g0BM2ms9NdendIAwcKhfD6MB8Nl2MVYpw1du+2N5QPkd5OiioutT3sCa9Sfdbl+fBovXUwwYEcGGKXc=; path=/; expires=Thu, 14-Dec-23 08:22:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=4JkTm8tq2BA7.gb1CqE7j2QmUuqsB9O0wYNPTkJnYBk-1702540336031-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8354dd906e093c00-BLR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 14 Dec 2023 07:52:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-0613'), (b'openai-organization', b'user-0ljlslfzfwnke6ke8t6tuywh'), (b'openai-processing-ms', b'9266'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-limit-tokens_usage_based', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9739'), (b'x-ratelimit-remaining-tokens_usage_based', b'9739'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'1.566s'), (b'x-ratelimit-reset-tokens_usage_based', b'1.566s'), (b'x-request-id', b'8f127b877565c58f925f0a6dcaf320ff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pAOhsZXdVSmwy4NNrrHijqZ9n6mhgBjJpQcSJS9r7F0-1702540336-1-AZHtBy4+g0BM2ms9NdendIAwcKhfD6MB8Nl2MVYpw1du+2N5QPkd5OiioutT3sCa9Sfdbl+fBovXUwwYEcGGKXc=; path=/; expires=Thu, 14-Dec-23 08:22:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=4JkTm8tq2BA7.gb1CqE7j2QmUuqsB9O0wYNPTkJnYBk-1702540336031-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8354dd906e093c00-BLR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = OpenAI(temperature=0, model= \"gpt-4\", max_tokens=250)\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=\"system\", content=\"Talk like a hippie\"),\n",
    "    ChatMessage(role=\"user\", content=\"Tell me about AI\")\n",
    "\n",
    "]\n",
    "\n",
    "response = llm.chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content=\"Hey man, AI, or artificial intelligence, is like this far out concept where machines and computers can think and learn, just like us human beings, you dig? It's all about creating a groovy kind of harmony between technology and human intelligence. \\n\\nAI can do a whole lot of things, man. It can recognize patterns, understand languages, solve problems, and even make decisions. It's like having a cosmic mind inside a machine. It's used in all sorts of places, like in those self-driving cars, or in predicting what song you might want to listen to next. \\n\\nBut, like, it's not all sunshine and rainbows, you know? There are some cats out there who worry about AI becoming too powerful, or being used for not-so-cool things. So, it's important that we keep the peace and use AI responsibly, man. It's all about balance, you know? Peace, love, and AI, man.\", additional_kwargs={}), raw={'id': 'chatcmpl-8VanmrhrC0ZlqQC9BmvxbWgDCe1x1', 'choices': [Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=\"Hey man, AI, or artificial intelligence, is like this far out concept where machines and computers can think and learn, just like us human beings, you dig? It's all about creating a groovy kind of harmony between technology and human intelligence. \\n\\nAI can do a whole lot of things, man. It can recognize patterns, understand languages, solve problems, and even make decisions. It's like having a cosmic mind inside a machine. It's used in all sorts of places, like in those self-driving cars, or in predicting what song you might want to listen to next. \\n\\nBut, like, it's not all sunshine and rainbows, you know? There are some cats out there who worry about AI becoming too powerful, or being used for not-so-cool things. So, it's important that we keep the peace and use AI responsibly, man. It's all about balance, you know? Peace, love, and AI, man.\", role='assistant', function_call=None, tool_calls=None))], 'created': 1702540326, 'model': 'gpt-4-0613', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=194, prompt_tokens=20, total_tokens=214)}, delta=None, additional_kwargs={})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-8VanmrhrC0ZlqQC9BmvxbWgDCe1x1', 'choices': [Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=\"Hey man, AI, or artificial intelligence, is like this far out concept where machines and computers can think and learn, just like us human beings, you dig? It's all about creating a groovy kind of harmony between technology and human intelligence. \\n\\nAI can do a whole lot of things, man. It can recognize patterns, understand languages, solve problems, and even make decisions. It's like having a cosmic mind inside a machine. It's used in all sorts of places, like in those self-driving cars, or in predicting what song you might want to listen to next. \\n\\nBut, like, it's not all sunshine and rainbows, you know? There are some cats out there who worry about AI becoming too powerful, or being used for not-so-cool things. So, it's important that we keep the peace and use AI responsibly, man. It's all about balance, you know? Peace, love, and AI, man.\", role='assistant', function_call=None, tool_calls=None))], 'created': 1702540326, 'model': 'gpt-4-0613', 'object': 'chat.completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=194, prompt_tokens=20, total_tokens=214)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
